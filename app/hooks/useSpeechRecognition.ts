"use client";

import { useState, useEffect, useCallback, useRef } from 'react';

interface IWindow extends Window {
  webkitSpeechRecognition: any;
  SpeechRecognition: any;
}

// ğŸš€ ã€è¿½åŠ ã€‘iOS/iPadOSåˆ¤å®šå®šæ•°
const isIOS = typeof navigator !== "undefined" && 
  (/iPhone|iPad|iPod/.test(navigator.userAgent) || 
  (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1));

export const useSpeechRecognition = () => {
  const [text, setText] = useState<string>('');
  const [isListening, setIsListening] = useState<boolean>(false);
  const recognitionRef = useRef<any>(null);

  useEffect(() => {
    if (typeof window === "undefined") return;

    const { webkitSpeechRecognition, SpeechRecognition } = window as unknown as IWindow;
    const SpeechRecognitionApi = SpeechRecognition || webkitSpeechRecognition;

    if (!SpeechRecognitionApi) return;

    const instance = new SpeechRecognitionApi();
    
    // ğŸš€ iOSå®‰å®šã®ãŸã‚ã€å˜ç™ºèªè­˜(false)ã§é‹ç”¨
    instance.continuous = false; 
    instance.lang = 'ja-JP';
    instance.interimResults = false; 

    instance.onstart = () => setIsListening(true);
    
    instance.onresult = (event: any) => {
      // ç¢ºå®šã—ãŸçµæœã®ã¿ã‚’å–å¾—
      const transcript = event.results[0][0].transcript;
      setText(transcript);
    };

    instance.onend = () => {
      setIsListening(false);
    };

    instance.onerror = (event: any) => {
      setIsListening(false);
      // iOSã§ã®ã‚¨ãƒ©ãƒ¼ï¼ˆç‰¹ã«'aborted'ã‚„'not-allowed'ï¼‰æ™‚ã«
      // å‹æ‰‹ã«å†èµ·å‹•ãƒ«ãƒ¼ãƒ—ã—ãªã„ã‚ˆã†ã€ã“ã“ã§ã¯çŠ¶æ…‹ç®¡ç†ã®ã¿ã«ç•™ã‚ã¾ã™
      console.warn("Speech recognition error:", event.error);
    };

    recognitionRef.current = instance;

    return () => {
      if (recognitionRef.current) recognitionRef.current.abort();
    };
  }, []);

  const startListening = useCallback(() => {
    if (!recognitionRef.current) return;

    // å‰ã®èªè­˜ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã¯ç¢ºå®Ÿã«æ­¢ã‚ã‚‹
    try {
      recognitionRef.current.stop();
    } catch (e) {}

    setText('');

    // ğŸš€ iOSã¯é€£ç¶šã—ãŸå‘¼ã³å‡ºã—ã«å¼±ã„ãŸã‚ã€å°‘ã—ã ã‘ãƒ‡ã‚£ãƒ¬ã‚¤ã‚’ç½®ã„ã¦ã‹ã‚‰é–‹å§‹
    const startDelay = isIOS ? 50 : 10;
    setTimeout(() => {
      try {
        recognitionRef.current.start();
      } catch (e) {
        // iOSã§æ—¢ã«ç¨¼åƒä¸­ã®ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã¯ç„¡è¦–
        console.warn("Speech recognition start failed:", e);
      }
    }, startDelay);
  }, []);

  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.abort();
      setIsListening(false);
    }
  }, []);

  const resetText = useCallback(() => {
    setText('');
  }, []);

  // ğŸš€ isIOS ã‚‚ä¸€ç·’ã«è¿”ã™ã“ã¨ã§ã€page.tsx å´ã§æŒ™å‹•ã‚’åˆ†å²ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™
  return { text, isListening, startListening, stopListening, resetText, isIOS };
};